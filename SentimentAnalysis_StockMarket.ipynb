{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Sentiment Analysis to Predict Stock Market"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives:\n",
    "\n",
    "- Learn how to get historic stock prices by Python.\n",
    "\n",
    "- Plot the stock prices.\n",
    "\n",
    "- Learn how to scrape financial news headlines from a financial news website.\n",
    "\n",
    "- Implement sentiment analysis on news' headlines.\n",
    "\n",
    "- Plot stock prices and sentiment scores to see the relationship between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install yfinance\n",
    "!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf    # library to access Yahoo! Finance\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify paths\n",
    "print(os.getcwd())  # print current working directory\n",
    "output_path = './data/stockmarket/'  # path to save data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pull stock prices of top 30 companies in Germany\n",
    "\n",
    "The list of the companies is available here: https://companiesmarketcap.com/germany/largest-companies-in-germany-by-market-cap/\n",
    "\n",
    "We will get stock prices data through library `yfinance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of companies in Germany\n",
    "tickers = ['SAP.DE', 'SIE.DE', 'DTE.DE', 'P911.DE', 'ALV.DE', 'VOW3.DE', 'MBG.DE', 'BMW.DE', 'MRK.DE', 'SHL.DE',\n",
    "             'BAYZF', 'DPW.DE', 'RAA.F', 'MUV2.DE', 'IFX.DE', 'BAS.DE', 'HLAG.DE', 'UN01.DE', 'DB1.DE', 'EOAN.DE', \n",
    "             'ADS.DE', 'HEN3.DE', 'BEI.DE', 'RWE.DE', 'EBK.DE', 'DTG.F', 'BNTX', 'HNR1.DE', 'SRT.DE', 'DB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get data\n",
    "def get_yahoo_data(tickers_list, period):\n",
    "    # Create an empty list to store data\n",
    "    data_df = pd.DataFrame(None)\n",
    "    \n",
    "    for ticker in tickers_list:\n",
    "        # Access ticker data\n",
    "        company_tkr = yf.Ticker(ticker)\n",
    "        # Define period of analysis\n",
    "        company_hist = company_tkr.history(period = period)\n",
    "        # Format dataframe\n",
    "        company_hist = company_hist.reset_index().rename(columns = {'index': 'Date'})\n",
    "        company_hist['Ticker'] = [ticker] * len(company_hist)\n",
    "        \n",
    "        # Concatenate two dataframes\n",
    "        data_df = pd.concat([data_df, company_hist], ignore_index = True)\n",
    "        \n",
    "    # Move the last column to the first position\n",
    "    ticker_col = data_df.iloc[:, -1]  # select the last column\n",
    "    data_df = pd.concat([ticker_col, data_df.iloc[:, :-1]], axis = 1)  # concatenate with the rest of the dataframe\n",
    "           \n",
    "     # Reuturn dataframe   \n",
    "    return pd.DataFrame(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stock prices of top 30 German companies with period of 5 years\n",
    "stock_prices_df = get_yahoo_data(tickers, '5y')\n",
    "\n",
    "# View the data\n",
    "stock_prices_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format column of Date\n",
    "stock_prices_df['Date'] = stock_prices_df['Date'].apply(lambda x: x.date())\n",
    "\n",
    "# View data\n",
    "stock_prices_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data as csv file\n",
    "stock_prices_df.to_csv(output_path + 'StockPrices_30GermanCompanies_YFinance.csv', header = True, sep = ';', index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scrape financial news headlines from FinViz\n",
    "\n",
    "The FinViz website is a great information provider about stock market.\n",
    "\n",
    "You can access the website: https://finviz.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from urllib.request import urlopen, Request\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape data and save it in a dictionary\n",
    "finviz_url = 'https://finviz.com/quote.ashx?t='\n",
    "news_tables = {}\n",
    "tickers = ['SAP', 'BNTX', 'DB']\n",
    "for ticker in tickers:\n",
    "    url = finviz_url + ticker\n",
    "    req = Request(url = url, headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36'}) \n",
    "    response = urlopen(req)    \n",
    "    # Read the contents of the file into 'html'\n",
    "    html = BeautifulSoup(response)\n",
    "    # Find 'news-table' in the Soup and load it into 'news_table'\n",
    "    news_table = html.find(id = 'news-table')\n",
    "    # Add the table to our dictionary\n",
    "    news_tables[ticker] = news_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's extract one example to see the structure of the created dictionary\n",
    "# Read several headlines for ‘SAP’ \n",
    "sap = news_tables['SAP']\n",
    "# Get all the table rows tagged in HTML with <tr> into ‘sap_tr’\n",
    "sap_tr = sap.findAll('tr')\n",
    "for i, table_row in enumerate(sap_tr):\n",
    "    # Read the text of the element ‘a’ into ‘link_text’\n",
    "    a_text = table_row.a.text\n",
    "    # Read the text of the element ‘td’ into ‘data_text’\n",
    "    td_text = table_row.td.text\n",
    "    # Print the contents of ‘link_text’ and ‘data_text’ \n",
    "    print(a_text)\n",
    "    print(td_text)\n",
    "    # Exit after printing 6 rows of data\n",
    "    if i == 5: \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the data into a list\n",
    "parsed_news = []\n",
    "# Iterate through the news\n",
    "for file_name, news_table in news_tables.items():\n",
    "    # Iterate through all tr tags in 'news_table'\n",
    "    for x in news_table.findAll('tr'):\n",
    "        # Read the text from each tr tag into text\n",
    "        # Get text from a only\n",
    "        text = x.a.get_text() \n",
    "        # Split text in the td tag into a list \n",
    "        date_scrape = x.td.text.split()\n",
    "        # if the length of 'date_scrape' is 1, load 'time' as the only element\n",
    "        if len(date_scrape) == 1:\n",
    "            time = date_scrape[0]\n",
    "            \n",
    "        # else load 'date' as the 1st element and 'time' as the second    \n",
    "        else:\n",
    "            date = date_scrape[0]\n",
    "            time = date_scrape[1]\n",
    "        # Extract the ticker from the file name, get the string up to the 1st '_'  \n",
    "        ticker = file_name.split('_')[0]\n",
    "        \n",
    "        # Append ticker, date, time and headline as a list to the 'parsed_news' list\n",
    "        parsed_news.append([ticker, date, time, text])\n",
    "\n",
    "# Print first 5 rows of news        \n",
    "parsed_news[:5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set column names\n",
    "columns = ['Ticker', 'Date', 'Time', 'Headline']\n",
    "\n",
    "# Convert parsed_news list into Dataframe\n",
    "stock_news_df = pd.DataFrame(parsed_news, columns = columns)\n",
    "\n",
    "# Convert date column into datetime\n",
    "stock_news_df['Date'] = pd.to_datetime(stock_news_df['Date']).dt.date\n",
    "\n",
    "# View data\n",
    "stock_news_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Construct Sentiment Classifications\n",
    "\n",
    "From the headlines from data `stocks_news_df`, we create several columns of sentiment classifications, emotions, scores,..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Sentiment classifiers with `pipline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import transformer model\n",
    "from transformers import pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment classification with values `POS`(positive), `NEU`(neutal) and `NEG`(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment classifier\n",
    "sentiment_classifier = pipeline(model = 'finiteautomata/bertweet-base-sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get sentiment\n",
    "def get_sentiment(text):\n",
    "    # Get sentiment prediction scores\n",
    "    try:\n",
    "        sentiment = sentiment_classifier(text)[0]['label']\n",
    "    except:\n",
    "        sentiment = 'Not classified'\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column namely 'Sentiment'\n",
    "stock_news_df['Sentiment'] = stock_news_df['Headline'].astype(str).apply(lambda x: get_sentiment(x))\n",
    "\n",
    "# View the data\n",
    "stock_news_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Emotion classifier with categorical values of emotions such as `joy, anger, fear, sadness, love,...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emotion classifier\n",
    "emotion_classifier = pipeline(\"text-classification\", model = 'bhadresh-savani/distilbert-base-uncased-emotion', return_all_scores = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to get emotion\n",
    "def get_emotion(text):\n",
    "    # Get emotion prediction scores\n",
    "    pred_scores = emotion_classifier(text)\n",
    "    \n",
    "    # Get emotion with highest prediction score\n",
    "    emotion = max(pred_scores[0], key = lambda x: x['score'])['label']\n",
    "    \n",
    "    return emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column of 'Emotion'\n",
    "stock_news_df['Emotion'] = stock_news_df['Headline'].astype(str).apply(lambda x: get_emotion(x))\n",
    "\n",
    "# View the data\n",
    "stock_news_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Sentiment Analysis with `nltk` (Natural Language Toolkits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import nltk\n",
    "nltk.downloader.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment score classifier\n",
    "sentiment_score_classifier = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the headlines and get the polarity scores using vader\n",
    "sentiment_scores = stock_news_df['Headline'].apply(sentiment_score_classifier.polarity_scores).tolist()\n",
    "\n",
    "# Convert the 'sentiment_scores' list of dicts into a DataFrame\n",
    "sentiment_scores_df = pd.DataFrame(sentiment_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the DataFrames of the news and the list of dicts\n",
    "stock_news_df = stock_news_df.join(sentiment_scores_df, rsuffix = '_right')\n",
    "\n",
    "# View the data\n",
    "stock_news_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Perform Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format Dataframe of prices\n",
    "stock_prices_df['Ticker'] = stock_prices_df['Ticker'].replace('SAP.DE', 'SAP')\n",
    "\n",
    "# Combine stock_prices_df and stock_news_df\n",
    "stocks_df = pd.merge(stock_news_df, stock_prices_df, how = 'inner', on = ['Ticker', 'Date'])\n",
    "\n",
    "# View the data\n",
    "stocks_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Pie plots of sentiment analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sentiment about three companies\n",
    "fig, axs = plt.subplots(1, 3, figsize = (15,5))\n",
    "\n",
    "for i, ticker in enumerate(stocks_df.Ticker.unique()):\n",
    "    # Select each company\n",
    "    temp_df = stocks_df[stocks_df.Ticker == ticker]\n",
    "    # Compute proportion of sentiment\n",
    "    counts = temp_df['Sentiment'].value_counts()\n",
    "    proportions = counts/counts.sum()*100\n",
    "    proportions = proportions.apply(lambda x: \"{:.2f}\".format(x) if isinstance(x, (float, int)) else x)\n",
    "    \n",
    "    # Creat pie chart \n",
    "    ## Define the colors for each label\n",
    "    colors = ['lightblue', 'salmon', 'navajowhite']\n",
    "\n",
    "    ## Define the properties of the text\n",
    "    textprops = {'color': 'white', 'fontsize': 12}\n",
    "\n",
    "    ## Plot\n",
    "    axs[i].pie(proportions.values, labels = proportions.index, wedgeprops = {'width': 0.8}, colors = colors, autopct = '%1.2f%%')\n",
    "\n",
    "    ## Add a title\n",
    "    axs[i].set_title(f'Sentiment of News about the company {ticker}')\n",
    "    \n",
    "plt.show();\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Bar plots of emotion distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the emotion distribution\n",
    "fig, axs = plt.subplots(1, 3, figsize = (20,5))\n",
    "\n",
    "for i, ticker in enumerate(stocks_df.Ticker.unique()):\n",
    "    # Select each company\n",
    "    temp_df = stocks_df[stocks_df.Ticker == ticker]\n",
    "\n",
    "    counts = temp_df['Emotion'].value_counts()\n",
    "\n",
    "    # Create the bar chart with the defined labels and values\n",
    "    axs[i].bar(counts.index, counts.values)\n",
    "\n",
    "    # Add a title to the bar chart\n",
    "    axs[i].set_title(f'Emotions of News about the company {ticker}')\n",
    "\n",
    "    # Add labels to the x and y axes\n",
    "    axs[i].set_xlabel('Emotion')\n",
    "    axs[i].set_ylabel('Count')\n",
    "\n",
    "# Show the bar chart\n",
    "plt.show();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Examine the relationship between sentiment scores and stock prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set plot style\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Price and Sentiment Scores\n",
    "for ticker in stocks_df.Ticker.unique():\n",
    "    # Subset of data for each company\n",
    "    stocks_df_sub = stocks_df[stocks_df.Ticker == ticker] \n",
    "    stocks_df_sub = stocks_df_sub[['Date', 'compound', 'Open', 'Close']]\n",
    "    # Convert the 'Date' column to a pandas datetime object\n",
    "    stocks_df_sub['Date'] = pd.to_datetime(stocks_df_sub['Date'])\n",
    "\n",
    "    # Group the data by month and mean the values\n",
    "    stocks_df_sub = stocks_df_sub.groupby(pd.Grouper(key = 'Date', freq = 'M')).mean()\n",
    "\n",
    "    # Reset index\n",
    "    stocks_df_sub.reset_index(inplace = True)\n",
    "\n",
    "    # Line plot\n",
    "    fig, ax = plt.subplots(figsize = (10, 6))\n",
    "    ax.plot(stocks_df_sub.Date, stocks_df_sub.Close, marker = '.' , color = 'darkgreen', label = 'Closing price')\n",
    "    ax.set_xlabel('Year-Month', fontsize = 14)\n",
    "    ax.set_ylabel('Closing Price ($)', fontsize = 14)\n",
    "    ax.set_title('Closing Price and Sentiment Score Over Time')\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    # make a plot with different y-axis using second axis object\n",
    "    ax2.plot(stocks_df_sub.Date, stocks_df_sub.compound, marker = '.', color = 'darkorange', label = 'Sentiment score')\n",
    "    ax2.set_ylabel(\"Sentiment Score\", fontsize = 14)\n",
    "\n",
    "    ax.legend(loc = \"lower right\", bbox_to_anchor = (0.5, -0.25), fancybox = True, ncol = 5, fontsize = 15, shadow = True,)\n",
    "    ax2.legend(loc = \"lower left\", bbox_to_anchor = (0.5, -0.25), fancybox = True, ncol = 5, fontsize = 15, shadow = True,)\n",
    "    plt.show();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Ran Aroussi (2023), *\"Download market data from Yahoo! Finance's API\"*, visit link: https://pypi.org/project/yfinance/\n",
    "\n",
    "2. Damian Boh (2020), *\"Sentiment Analysis of Stocks from Financial News using Python\"*, Medium, visit link: https://medium.datadriveninvestor.com/sentiment-analysis-of-stocks-from-financial-news-using-python-82ebdcefb638\n",
    "\n",
    "3. Youtube Channel CodeXplore (2021), *\"Hướng Dẫn Làm Data Visualisation Project với Matlplotlib và Python\"*, visit link: https://www.youtube.com/watch?v=N_7A3KPZIQw\n",
    "\n",
    "4. Youtube Channel Thu Vu Data Analytics (2023), *\"Building a Chatbot with ChatGPT API and Reddit Data\"*, visit link: https://www.youtube.com/watch?v=EE1Y2enHrcU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
